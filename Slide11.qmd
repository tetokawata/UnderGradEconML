---
title: "罰則付き回帰モデル"
author: "川田恵介"
format: 
  revealjs:
    html-math-method: katex
    slide-number: true
    incremental: true
self-contained: true
self-contained-math: true
execute: 
  warning: false
  message: false
  eval: true
  echo: false
---

```{r}
#| label: SetUp

pacman::p_load(
  tidyverse,
  quanteda,
  quanteda.textstats,
  SuperLearner,
  wordcloud2,
  htmlwidgets,
  gamlr,
  nnet,
  neuralnet
  )

Data <- read_csv("Public/Text.csv")

Tokes <- Data |> 
  corpus(
  text_field = "Title") |> 
  tokens() |>
  tokens_remove(
    c(
      stopwords::stopwords("ja", source = "marimo"),
      stopwords::stopwords("ja", source = "stopwords-iso")
      )
  )

Seqs <- Tokes |> 
    textstat_collocations(min_count = 2, tolower = FALSE)

Seqs <- Seqs[Seqs$z > 5,]

TokesSeq <- Tokes |> 
  tokens_select(min_nchar = 2) |> 
  tokens_compound(Seqs, concatenator = '')
```

# 罰則付き回帰モデル

- $X$ の数が多い場合、線形予測モデルの推定は困難

- 決定木(RandomForest)は有力な代替案だが、$X$ の数が極めて多くなると機能しなくなる

- 有力な選択肢は、線形予測モデル推定の改良

## 復習

- 線形予測モデル $$g(X)=\beta_0+..+\beta_LX_L$$

- データに当てはめるように推定

    - $\beta$ の数が多くなると、予測性能が悪化
    
    - 過剰適合
    
## イメージ

```{r, dev='ragg_png'}
tibble(
  NumX = seq(-25,25),
  不適合度 = 1/(NumX + 26),
  Target = "データへの適合"
  ) |> 
  bind_rows(
    tibble(
      NumX = seq(-25,25),
      不適合度 = NumX^2/300 + 0.3,
      Target = "母集団への適合"
  )
  ) |> 
  mutate(
    Xの数 = NumX + 26
  ) |> 
  ggplot(
    aes(
      x = Xの数,
      y = 不適合度,
      color = Target
    )
  ) +
  theme_bw() +
  geom_line() +
  theme(
    legend.position = "bottom"
  )
```


## 対応

- 環境税などと同じアイディア

- 自動車は便利な道具であるが、同時に排気ガス/渋滞など負の外部性が存在

    - 何も対応しないと保有台数が過大になりうる
    
- 適切な水準に誘導するために、自動車税を貸す

- **何も対応しないと複雑なモデルになりすぎるので、複雑性に課税する**

## 罰則付き回帰

- 線形モデル $g(X)$ を、以下を最小化するように推定する $$データへの当てはまり + \underbrace{\lambda\times 複雑性}_{複雑性への課税}$$

- $\lambda:$ 課税額

    - 交差推定で決定 
    
    - 母集団の当てはまり最大化を目指す
    
## 複雑性の指標

- Ridge: $\beta_1^2+..+\beta_L^2$

- LASSO: $|\beta_1|+..+|\beta_L|$

- OLS: "0"

## LASSOの利点

- 予測において重要ではない$\beta$ を、厳密に0にできる

    - 重要ではない変数をモデルから除外する
    
- OLSやRidgeでは、厳密に0にはできない

## テキスト分析への有効性

- 単語数が多い $\rightarrow$ $X$ が多い $\rightarrow$ 重要ではない単語も多いかも?

- LASSOが有効な場面も多い

## 実例

```{r}
X <- TokesSeq |> 
  dfm() |> 
  dfm_trim(
    min_docfreq = 10
  ) |> 
  convert(
    "data.frame"
  )

X <- select(X, -doc_id)

#names(X) <- str_c("Word",1:ncol(X))

Y <- if_else(Data$Type == "一般",1,0)

CV <- glmnet::cv.glmnet(
  x = X |> as.matrix(),
  y = Y
)

Fit <- glmnet::glmnet(
  x = X |> as.matrix(),
  y = Y,
  lambda = CV$lambda.min
)

coef(Fit)
```

## 注意: 統計的推論

- 解釈しやすそうなモデルが出てくるが、

    - 母集団の構造への含意は限定的
    
- $Y$ と関係性が強い変数であったとしても、互いに相関が強ければ、脱落しがち

- 推定誤差の計算は困難

## 数値例

- $E[Y|X1,X2]=X1+X2$

- $E[X2|X1]=X1$

## 数値例

```{r}
SimData <- function(i){
  set.seed(i)
  TempData <- tibble(
    X1 = runif(100),
    X2 = X1 + rnorm(100)
  ) |> 
    mutate(
      Y = X1 + X2 + rnorm(100,0,5)
    )
  return(TempData)
}

Est <- function(i){
  TempData <- SimData(i)
  X <- model.matrix(~ 0 + X1 + X2, TempData)
  Y <- TempData$Y
  Fit <- gamlr(X,Y)
  Temp <- Fit |> coef()
  Result <- tibble(
    ID = i,
    B1 = Temp[2],
    B2 = Temp[3]
  )
  return(Result)
}

map_dfr(1:100,Est) |> 
  ggplot(
    aes(
      y = ID,
      x = B1,
      color = "B1"
    )
  ) +
  theme_bw() +
  geom_point() +
  geom_point(
    aes(
      x = B2,
      color = "B2"
    )
  )
```


## まとめ

- 事例数を大きく超える $X$ から、予測モデルを構築することは困難なチャレンジ

    - 一つのアプローチは、LASSO
    
    - ただし解釈は慎重に
    
# 発展: ニューラルネット

- 線形モデルの拡張

- "人間の脳みその構造を模したモデル"

    - "AI"

## アイディア

- モデルの集計

1. 複数の中間予測モデル $g_1(X)..g_M(X)$ (Hidden Layer)を推定

2. 中間予測モデルの予測値から、最終予測モデル $g(g_1(X),..,g_M(X))$ を推定

- $g$ は一般化された線形モデル $g(X_1,..,X_L)=g(\beta_0+..+\beta_LX_L)$

- 中間モデルの数 $=$ 複雑性を規定

## 実例

```{r, dev='ragg_png'}
X <- TokesSeq |> 
  dfm() |> 
  dfm_trim(
    min_docfreq = 5
  ) |> 
  convert(
    "data.frame"
  )

X <- select(X, -doc_id)

#names(X) <- str_c("Word",1:ncol(X))

Y <- if_else(Data$Type == "一般",1,0)

Fit <- nnet::nnet(
  x = X,
  y = Y,
  size = 1,
  trace = FALSE,
  linout = FALSE
  )

NeuralNetTools::plotnet(Fit)
```


## 実例

```{r, dev='ragg_png'}
X <- TokesSeq |> 
  dfm() |> 
  dfm_trim(
    min_docfreq = 10
  ) |> 
  convert(
    "data.frame"
  )

X <- select(X, -doc_id)

#names(X) <- str_c("Word",1:ncol(X))

Y <- if_else(Data$Type == "一般",1,0)

Fit <- nnet::nnet(
  x = X,
  y = Y,
  size = 3,
  trace = FALSE,
  linout = FALSE
  )

NeuralNetTools::plotnet(Fit)

```

## 実例

```{r}
Fit <- CV.SuperLearner(
  X = X,
  Y = Y,
  SL.library = c(
    "SL.mean",
    "SL.lm",
    "SL.glmnet",
    "SL.nnet"
  )
)

Fit |> summary()
```

## DeepLearning

- 中間予測モデルを多層にする

- 人間の脳の構造に似ているそうです。。。

    - テキストや画像データについて、高い精度

## 実例

```{r, dev='ragg_png'}
library(devtools)

source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')


TempX <- X |> 
    rename(
      COVID19 = `covid-19`
    )

Fit <- neuralnet(
  str_c("Y~",str_c(names(TempX),collapse = "+")) |> 
    as.formula(),
   TempX |> 
    mutate(Y = Y),
  hidden=c(3,3),
  linear.output=T
  )

plot.nnet(Fit)
```

## 性能

```{r}
SuperLearner(
  Y = Y,
  X = X,
  SL.library = c(
    "SL.mean",
    "SL.lm",
    "SL.glmnet",
    "SL.nnet"
  )
)
```

## まとめ

- 盛んに成果が報告される

    - 一部分野では非常に高いパフォーマンス
    
    - どの程度まで一般性があるかは不透明
    
- パラメータ設定が難しい
