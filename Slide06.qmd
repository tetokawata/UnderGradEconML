---
title: "記述統計量の推定"
subtitle: "経済学のための機械学習入門"
author: "川田恵介"
format: 
  revealjs:
    chalkboard: true
    html-math-method: katex
    slide-number: true
    incremental: true
execute: 
  warning: false
  message: false
  eval: true
  echo: false
---

# 母集団の推論

```{r}
pacman::p_load(
  tidyverse,
  SuperLearner,
  rpart,
  ranger,
  patchwork
)

Noise <- 10
FigLower <- -20
FigUpper <- 60

N <- 100

SimData <- function(i,n,a){
  set.seed(i)
  TempData <- tibble(
    X = sample(0:5,n,replace = TRUE),
    D = if_else(
      X >= -1 & X <= 1,
      sample(0:1,n,replace = TRUE,prob = c(1-a,a)),
      sample(0:1,n,replace = TRUE)
    ),
    TrueY = 5*D + X^2,
    Y = TrueY + runif(n,-Noise,Noise)
  )
  return(TempData)
}
```

- データ分析の基本的発想: 事例を集計することで、観察できない要因の偏りの影響を緩和

    - 予測モデルへの影響はどうしても残る
    
- 新しい発想: 予測モデル自体を"集計"する

## 教師付き学習の問題点

- 5000サンプル

```{r}
N <- 5000

FigPop <- SimData(1,5000,0.5) |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      group = D,
      color = factor(D)
    )
  ) +
  theme_bw() +
  geom_smooth(
    method = "lm",
    formula = y ~ I(x^2),
    se = FALSE
  ) +
  ylab("E[Y|D,X]") +
    ylim(-5,30)

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a)
  TempPred <-  ranger(
        Y ~ X + D,
        TempData) |> 
        predict(
          TempData
        )
  TempData |> 
    mutate(
      Pred = TempPred$predictions
    ) |> 
    ggplot(
      aes(
        x = X,
        y = Pred,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_line() +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-5,30)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```

## 教師付き学習の問題点

- 50000サンプル

```{r}
N <- 50000

FigPop <- SimData(1,5000,0.5) |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      group = D,
      color = factor(D)
    )
  ) +
  theme_bw() +
  geom_smooth(
    method = "lm",
    formula = y ~ I(x^2),
    se = FALSE
  ) +
  ylab("E[Y|D,X]") +
    ylim(-5,30)

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a)
  TempPred <-  ranger(
        Y ~ X + D,
        TempData) |> 
        predict(
          TempData
        )
  TempData |> 
    mutate(
      Pred = TempPred$predictions
    ) |> 
    ggplot(
      aes(
        x = X,
        y = Pred,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_line() +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-5,30)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```

## まとめ

- 代表的な教師付き学習による予測モデルは、母平均とは"一致しない"

    - 事例数が"無限大"になる必要がある
    
- 限られた事例数において推定されるモデルと、母平均関数はどのように乖離するのか？

    - 極めて不透明
    
- 推定されたモデルから、母平均の特徴を"推論"することは極めて困難
  

# 伝統的な計量経済学のアプローチ

- 母平均との関係性が"明確"にできる、母集団の"要約(記述)統計量"を推定

    - 機械学習も応用可能

## 要約: 100事例

```{r}
N <- 100

FigPop <- SimData(1,5000,0.5) |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      group = D,
      color = factor(D)
    )
  ) +
  theme_bw() +
  geom_smooth(
    method = "lm",
    formula = y ~ I(x^2),
    se = FALSE
  ) +
  ylab("E[Y|D,X]") +
    ylim(-15,40)

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a) |> 
    mutate(MeanY = mean(Y),
           .by = c(X,D))
  TempData |> 
    ggplot(
      aes(
        x = X,
        y = MeanY,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_point(
      aes(
        y = Y
      ),
      alpha = 0.5
    ) +
    geom_point() +
    geom_line() +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-15,40)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```

## 要約: 1000事例

```{r}
N <- 1000

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a) |> 
    mutate(MeanY = mean(Y),
           .by = c(X,D))
  TempData |> 
    ggplot(
      aes(
        x = X,
        y = MeanY,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_point() +
    geom_line() +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-15,40)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```


## Best Linear Projection

- 最善の線形近似: $E_P[Y|X]$ を可能な限り再現した**仮想的な**一直線
    
$$BLP(X)=\beta_0+\beta_1X_1+..+\beta_LX_L$$

    - $\beta:$ パラメータ

- 母集団において、以下を最小化するように設定

$$E_P[(Y-BLP(X))^2]$$

## BLPの推定

- データに合うように $g(X)=\beta_0+..+\beta_LX_L$ を推定する

    - 二乗誤差 $E[(Y-g(X))^2]$ の最小化

- 事例数に比べて、十分に単純なモデル ($\beta$ の数が少ない) であれば、非常に優れた方法

    - 計量経済学や統計学の講義で確実に学ぶ

## BLPの推定: 1000事例

```{r}
N <- 1000

FigPop <- SimData(1,5000,0.5) |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      group = D,
      color = factor(D)
    )
  ) +
  theme_bw() +
  geom_smooth(
    method = "lm",
    formula = y ~ I(x^2),
    se = FALSE,
    size = 0.5
  ) +
  geom_smooth(
    method = "lm",
    formula = y ~ x,
    se = FALSE
  ) +
  ylab("E[Y|D,X]") +
    ylim(-15,40)

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a) |> 
    mutate(MeanY = mean(Y),
           .by = c(X,D)) |> 
    mutate(
      Pred = lm(Y ~ D + X, SimData(i,n,a))$fitted
    )
  TempData |> 
    ggplot(
      aes(
        x = X,
        y = MeanY,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_point() +
    geom_line(
      aes(
        y = Pred
      )
    ) +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-15,40)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```


## BLPの推定: 200事例

```{r}
N <- 200

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a) |> 
    mutate(MeanY = mean(Y),
           .by = c(X,D)) |> 
    mutate(
      Pred = lm(Y ~ D + X, SimData(i,n,a))$fitted
    )
  TempData |> 
    ggplot(
      aes(
        x = X,
        y = MeanY,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_point() +
    geom_line(
      aes(
        y = Pred
      )
    ) +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-15,40)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```

## Well-specified model

- **特殊**なケース: $E_P[Y|X]=BLP(X)$

    - 入門的な教科書が想定
    
- 例: $E_P[Y|X]=X^2$ ならば

$$BLP(X)=\underbrace{\beta_0}_{=0}+\underbrace{\beta_1}_{=0}X+\underbrace{\beta_2}_{=1}\underbrace{X^2}_{:=X_2}$$

## 母平均の推定: 200事例

```{r}
N <- 200

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a) |> 
    mutate(MeanY = mean(Y),
           .by = c(X,D)) |> 
    mutate(
      Pred = lm(Y ~ 0 + D + I(X^2), SimData(i,n,a))$fitted
    )
  TempData |> 
    ggplot(
      aes(
        x = X,
        y = MeanY,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_point() +
    geom_line(
      aes(
        y = Pred
      )
    ) +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
    ylim(-15,40)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```

## まとめ

- データではなく、研究者が推定するモデルを設定する

- 母平均関数そのものではなく、単純化したBLPを推定している

    - ハードルの低いゴール

    - "安定"する

    - データへの依存度が減り、異なる分析者間で推定結果が似てくる

- 適切かつ単純なBLPを設定できれば、 母平均を優れた推定値

    - 非現実的!?
    

# 予測研究への応用

- 教師付き学習の一つの手法

    - スムーズな母平均関数に対する、有力な手法

## 例: RandomForest VS OLS

- 500サンプル

```{r}
N <- 500

FigPop <- SimData(1,5000,0.5) |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      group = D,
      color = factor(D)
    )
  ) +
  theme_bw() +
  geom_smooth(
    method = "lm",
    formula = y ~ I(x^2),
    se = FALSE
  ) +
  ylab("E[Y|D,X]") +
  ylim(-5,35)

SimFig <- function(i,n,a){
  TempData <- SimData(i,n,a)
  TempPred <-  ranger(
        Y ~ X + D,
        TempData) |> 
        predict(
          TempData
        )
  TempPredOLS <-  lm(
        Y ~ X + D,
        TempData) |> 
        predict(
          TempData
        )
  TempData |> 
    mutate(
      Pred = TempPred$predictions,
      PredOLS = TempPredOLS
    ) |> 
    ggplot(
      aes(
        x = X,
        y = Pred,
        group = factor(D),
        color = D |> factor()
      )
    ) +
    theme_bw() +
    geom_line(
      alpha = 0.5
    ) +
    geom_line(
      aes(
        y = PredOLS
      )
    ) +
    theme(
      legend.position = "none"
    ) +
    ylab("") +
  ylim(-5,35)
}

FigPop | (SimFig(1,N,0.5) + SimFig(2,N,0.5))/(SimFig(3,N,0.5) + SimFig(4,N,0.5))
```

## 性質の比較

- $X=4$ を予想

$$Y-g(X=4)=\underbrace{Y-E_P[Y|X=4]}_{どうしようもない個人差}$$

$$+\underbrace{E_P[Y|X=4]-\underbrace{g_{\infty}(X=4)}_{事例数が無限大ある場合の予測値}}_{(母集団における)近似誤差}$$

$$+\underbrace{g_{\infty}(X=4)-g(X=4)}_{推定誤差}$$

## RandomForest/決定木

$$Y-g(X=4)=Y-E_P[Y|X=4]$$

$$+\underbrace{E_P[Y|X=4]-g_{\infty}(X=4)}_{\simeq 0}$$

$$+\underbrace{g_{\infty}(X=4)-g(X=4)}_{?}$$


## シンプルなOLS

$$Y-g(X=4)=Y-E_P[Y|X=4]$$

$$+\underbrace{E_P[Y|X=4]-g_{\infty}(X=4)}_{?}$$

$$+\underbrace{g_{\infty}(X=4)-g(X=4)}_{\sim 正規分布}$$


## まとめ

- データ主導でモデルを設定する: RandomForest/Tree

    - 事例数が増えれば、勝手に複雑なモデルが推定されるので、誤差は一般に少ない
    
        - 予測研究における明確な利点
    
    - 推定誤差がどうなるかわからない

# 大標本理論に基づく推論

- ランダムサンプリングの仮定が持つ含意は？

    - 母集団への詳細な仮定なしで、BLPを推論できる

## Well-specified model

- "入門教科書"的な問題設定

- $g(D,X)=\beta_0+\beta_DD+\beta_1X_1+..+\beta_LX_L$

-  $E_P[Y|D,X]=g(D,X)$ を達成する $\beta^P$ が存在

## N = 10

```{r FitWellModelSmall}
N <- 10

TempSim <- function(i,n){
  TempFit <- lm(
    Y ~ D + I(X^2),
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Beta = TempFit$coefficients[2],
      ID = i,
      N = n
    )
  return(TempResult)
}

map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  ) |> 
  ggplot(
    aes(
      x = Beta,
      y = ID
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_point() +
  xlim(-50,75)
```

- 100名研究者が独立して研究 (事例数 $= 10$)

## N = 200

```{r FitWellModelMiddle}
N <- 200

TempSim <- function(i,n){
  TempFit <- lm(
    Y ~ D + I(X^2),
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Beta = TempFit$coefficients[2],
      ID = i,
      N = n
    )
  return(TempResult)
}

map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  ) |> 
  ggplot(
    aes(
      x = Beta,
      y = ID
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_point() +
  xlim(-50,75)
```

## N = 5000

```{r FitWellModelLarge}
N <- 5000

TempSim <- function(i,n){
  TempFit <- lm(
    Y ~ D + I(X^2),
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Beta = TempFit$coefficients[2],
      ID = i,
      N = n
    )
  return(TempResult)
}

map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  ) |> 
  ggplot(
    aes(
      x = Beta,
      y = ID
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_point() +
  xlim(-50,75)
```

## 信頼区間

- 「推定値 $=$ 真の値」を前提に議論を始めると、"100%"間違う

    - 事例数が無限でない限り、絶対に乖離

    - 独立した研究者間での合意も不可能

- ハードルを下げる

    - 大多数(典型的には95%)の研究者について、真の値を含む区間(信頼区間)を計算する

## 不適切な区間

```{r dev='ragg_png'}
N <- 5000
n <- 100
i <- 1
TempSim <- function(i,n){
  TempFit <- fixest::feols(
    Y ~ D + I(X^2),
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Coef = TempFit$coeftable[2,1],
      StanError = TempFit$coeftable[2,2],
      ID = i,
      N = n
    )
  return(TempResult)
}

TempResult <- map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  )

StrickCI <- qnorm(1 - (0.00005/2))
FuzzyCI <- qnorm(1 - (0.5/2))


Fig1 <- 
  TempResult |> 
  mutate(
    Alert = if_else(
      Coef - StrickCI*StanError > 5 |
        Coef + StrickCI*StanError < 5,
      "Wrong!!!",
      "OK"
    )
  ) |> 
  ggplot(
    aes(
      x = Coef,
      xmin = Coef - StrickCI*StanError,
      xmax = Coef + StrickCI*StanError,
      y = ID,
      color = Alert
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_pointrange() +
  xlab("広すぎる") +
  theme(legend.position = "none")

Fig2 <- 
  TempResult |> 
  mutate(
    Alert = if_else(
      Coef - FuzzyCI*StanError > 5 |
        Coef + FuzzyCI*StanError < 5,
      "Wrong!!!",
      "OK"
    )
  ) |> 
  ggplot(
    aes(
      x = Coef,
      xmin = Coef - FuzzyCI*StanError,
      xmax = Coef + FuzzyCI*StanError,
      y = ID,
      color = Alert
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_pointrange() +
  xlab("狭すぎる") +
  ylab("")

Fig1 + Fig2
```

## 漸近性質の活用

- 信頼区間を計算するには、推定値の分布(研究者間の散らばり具合)への仮定が必要

    - 本当の分布は、母分布に依存

- 代表的なアプローチは、サンプリング方法への仮定(ランダムサンプリング)"のみ"に基づいて導出される、漸近性質(サンプルサイズがある程度大きければ、近似的になりたつ性質)を活用

## 漸近正規性

- サンプルサイズがある程度大きければ、正規分布で近似できる

    - 真の値よりも、"早め"に収束する

## 漸近正規性

```{r dev = 'ragg_png'}
tibble(
  X = seq(0,10,length.out = 100)
  ) |> 
  mutate(y = dnorm(X,5)) |> 
  ggplot(aes(X, y)) + 
  theme_bw() +
  geom_area(fill = "sky blue") +
  gghighlight::gghighlight(X >= 5 - 1.96*(1) & X <= 5 + 1.96*(1)) +
  geom_vline(
    aes(linetype = "真の値",
        xintercept = 5)
    ) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()
        ) +
  xlab("推定値")
```

- 注意: 真の値からの"距離"だけわかる

## 95%信頼区間: 2000事例

```{r FitWellModelLargeCI}
N <- 2000

TempSim <- function(i,n){
  TempFit <- fixest::feols(
    Y ~ D + I(X^2),
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Coef = TempFit$coeftable[2,1],
      StanError = TempFit$coeftable[2,2],
      ID = i,
      N = n
    )
  return(TempResult)
}

map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  ) |> 
  mutate(
    Alert = if_else(
      Coef - 1.96*StanError > 5 |
        Coef + 1.96*StanError < 5,
      "Wrong!!!",
      "OK"
    )
  ) |> 
  ggplot(
    aes(
      x = Coef,
      xmin = Coef - 1.96*StanError,
      xmax = Coef + 1.96*StanError,
      y = ID,
      color = Alert
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_pointrange() +
  xlab("Well-specified (N = 5000)") +
  xlim(0,10)

```

## サンプルサイズの影響: 200事例

```{r FitWellModelSmallCI}
N <- 200

TempSim <- function(i,n){
  TempFit <- fixest::feols(
    Y ~ D + I(X^2),
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Coef = TempFit$coeftable[2,1],
      StanError = TempFit$coeftable[2,2],
      ID = i,
      N = n
    )
  return(TempResult)
}

map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  ) |> 
  mutate(
    Alert = if_else(
      Coef - 1.96*StanError > 5 |
        Coef + 1.96*StanError < 5,
      "Wrong!!!",
      "OK"
    )
  ) |> 
  ggplot(
    aes(
      x = Coef,
      xmin = Coef - 1.96*StanError,
      xmax = Coef + 1.96*StanError,
      y = ID,
      color = Alert
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_pointrange() +
  xlab("Well-specified (N = 5000)") +
  xlim(0,10)

```

## Misspecified model

- $g(D,X)=\beta_0+\beta_DD+\beta_1X_1+..+\beta_LX_L$

    - $\beta$ を推定

- $\beta$ をどう選んでも、 $E_P[Y|D,X]\neq g(D,X)$ (近似誤差)

    - BLPについて信頼区間を提供

## 例: BLP

```{r}
SimData(1,2000,0.5) |> 
  ggplot(
    aes(
      x = X,
      y = TrueY,
      color = D |> factor(),
      group = D |> factor()
    )
  ) +
  theme_bw() +
  geom_smooth(
    method = "lm",
    formula = y ~ x
  ) +
  geom_smooth(
    aes(
      y = TrueY
    ),
    method = "lm",
    formula = y ~ I(x^2),
    size = 0.5
  )
```

## 95%信頼区間: 2000事例

```{r FitMissModelCI}
N <- 2000

TempSim <- function(i,n){
  TempFit <- fixest::feols(
    Y ~ D + X,
    SimData(i,n,0.5)
    )
  TempResult <-
    tibble(
      Coef = TempFit$coeftable[2,1],
      StanError = TempFit$coeftable[2,2],
      ID = i,
      N = n
    )
  return(TempResult)
}

map_dfr(
  1:100, 
  function(i){TempSim(i,N)}
  ) |> 
  mutate(
    Alert = if_else(
      Coef - 1.96*StanError > 5 |
        Coef + 1.96*StanError < 5,
      "Wrong!?",
      "OK"
    )
  ) |> 
  ggplot(
    aes(
      x = Coef,
      xmin = Coef - 1.96*StanError,
      xmax = Coef + 1.96*StanError,
      y = ID,
      color = Alert
    )
  ) +
  geom_vline(
    xintercept = 5
  ) +
  theme_bw() +
  geom_pointrange() +
  xlab("Misspecified (N = 5000)") +
  xlim(0,10)

```

## まとめ

- ランダムサンプリングの仮定のみで、BLPについての信頼区間を導出できる

    - 大部分の研究者が真の値を含んだ区間を得られる
    
- BLPが"研究関心"となる母集団の特徴を捉えているのであれば、有益な方法

    - 予測の手法としては問題があっても**関係ない**
    
- BLP以外の記述統計量を推定したい場合は?
